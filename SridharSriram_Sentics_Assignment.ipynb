{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTay6bXBLJyt",
        "outputId": "51c2bcf6-0a2f-4c2d-bf6a-88992103be78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total valid entries in the CSV file: 4526\n",
            "Processing complete. Fused data saved to: output_data_file.csv\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "\n",
        "def parse_timestamp(timestamp_str):\n",
        "    try:\n",
        "        return datetime.strptime(timestamp_str, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "    except ValueError as e:\n",
        "        print(f\"Error parsing timestamp {timestamp_str}: {e}\")\n",
        "        return None\n",
        "\n",
        "def parse_entry(entry):\n",
        "    try:\n",
        "        timestamp = parse_timestamp(entry[0])\n",
        "        obj_id = entry[1]\n",
        "        x = float(entry[2])\n",
        "        y = float(entry[3])\n",
        "        unique_id = entry[4] if entry[4] != 'temp' else '0'  # Handle 'temp' case\n",
        "        sensor_id = entry[5] if len(entry) > 5 else None  # Handle optional sensor_id\n",
        "\n",
        "        return [timestamp, obj_id, x, y, unique_id, sensor_id]\n",
        "    except ValueError as e:\n",
        "        print(f\"Error parsing entry {entry}: {e}\")\n",
        "        return None\n",
        "\n",
        "def cluster_data(data):\n",
        "    clusters = []\n",
        "    unique_id_clusters = defaultdict(list)\n",
        "\n",
        "    for entry in data:\n",
        "        if entry is None:\n",
        "            continue\n",
        "\n",
        "        timestamp, obj_id, x, y, unique_id, sensor_id = entry\n",
        "\n",
        "        # Check if the object is already in a cluster\n",
        "        found_cluster = None\n",
        "        for cluster in clusters:\n",
        "            for point in cluster:\n",
        "                if point[4] == unique_id:\n",
        "                    found_cluster = cluster\n",
        "                    break\n",
        "            if found_cluster:\n",
        "                break\n",
        "\n",
        "        if found_cluster:\n",
        "            # Add the current point to the existing cluster\n",
        "            found_cluster.append([x, y, sensor_id])\n",
        "            # Update the timestamp for the cluster\n",
        "            found_cluster[0][0] = (found_cluster[0][0] + timestamp) / 2\n",
        "            # Update the unique_id_clusters dictionary\n",
        "            unique_id_clusters[unique_id].append(found_cluster)\n",
        "        else:\n",
        "            # Create a new cluster\n",
        "            new_cluster = [[timestamp, obj_id, x, y, unique_id, sensor_id, []]]\n",
        "            clusters.append(new_cluster)\n",
        "            # Update the unique_id_clusters dictionary\n",
        "            unique_id_clusters[unique_id].append(new_cluster)\n",
        "\n",
        "    return clusters, unique_id_clusters\n",
        "\n",
        "def fuse_clusters(clusters):\n",
        "    fused_data = []\n",
        "\n",
        "    for cluster in clusters:\n",
        "        f_timestamp = cluster[0][0]\n",
        "        f_id = hash(tuple(cluster[0][1:5]))  # Randomly generate f_id based on obj_id, x, y, and unique_id\n",
        "        f_u_id = cluster[0][4]  # Use unique_id\n",
        "\n",
        "        # Flatten the cluster data for cluster_data field\n",
        "        cluster_data = [point[2:5] + [point[5]] for point in cluster[1:]]\n",
        "\n",
        "        fused_data.append([f_timestamp, f_id, cluster_data, f_u_id])\n",
        "\n",
        "    return fused_data\n",
        "\n",
        "def save_to_csv(data, output_file):\n",
        "    with open(output_file, 'a', newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerows(data)\n",
        "\n",
        "def main(input_file, output_file):\n",
        "    try:\n",
        "        with open(input_file, 'r') as csvfile:\n",
        "            csv_reader = csv.reader(csvfile)\n",
        "            next(csv_reader)  # Skip the header row\n",
        "            data = [parse_entry(row) for row in csv_reader]\n",
        "\n",
        "        # Filter out None values (entries that could not be parsed)\n",
        "        data = [entry for entry in data if entry is not None]\n",
        "\n",
        "        print(f\"Total valid entries in the CSV file: {len(data)}\")\n",
        "\n",
        "        if not data:\n",
        "            print(\"No valid entries found. Exiting.\")\n",
        "            return\n",
        "\n",
        "        # Sort the data based on timestamp\n",
        "        data.sort(key=lambda x: x[0])\n",
        "\n",
        "        # Cluster the data\n",
        "        clusters, _ = cluster_data(data)\n",
        "\n",
        "        # Fuse the clusters\n",
        "        fused_data = fuse_clusters(clusters)\n",
        "\n",
        "        # Save the fused data to a new CSV file\n",
        "        save_to_csv(fused_data, output_file)\n",
        "        print(\"Processing complete. Fused data saved to:\", output_file)\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Please provide a valid input file path.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "main('/content/test_Data_1.csv', 'output_data_file.csv')\n"
      ]
    }
  ]
}